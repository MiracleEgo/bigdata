[TOC]

# [秒杀系统设计教程1](https://juejin.im/post/5dd09f5af265da0be72aacbd#heading-6)

# [秒杀系统架构分析与实战](https://www.jianshu.com/p/df4fbecb1a4b)

# 项目架构

![img](https://mmbiz.qpic.cn/mmbiz_jpg/iaIdQfEric9TxReHn5AXmsdWIlDhe6MNFyxgG4oH3cvhzVhAEgGtdQZQDhNdofyB4rSLynPSkAx60yluDPfE95ibA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

```
   本系统主要分为展示层,服务层,持久层.表现层顾名思义就是用来页面展示的,比如后台管理系统的页面,项目(商城首页)主页面等,只是作为展示,不提供任何服务
   展示层和服务层
```

# [单点登陆](https://mp.weixin.qq.com/s/drPVkRbCsDIlX6Ls2pDmqA)

* 单点登录就是**在多个系统中，用户只需一次登录，各个系统即可感知该用户已经登录。**

* 一般我们单系统实现登录会这样做：

  - **登录**：将用户信息保存在Session对象中

  - - 如果在Session对象中能查到，说明已经登录
    - 如果在Session对象中查不到，说明没登录（或者已经退出了登录）

  - **注销（退出登录）**：从Session中删除用户的信息

  - **记住我（关闭掉浏览器后，重新打开浏览器还能保持登录状态）**：配合Cookie来用

## [解决系统之间Session不共享问题](https://mp.weixin.qq.com/s/drPVkRbCsDIlX6Ls2pDmqA)

* 把Session数据放在Redis中（使用Redis模拟Session）

* 其他子系统登录时，**请求SSO（登录系统）进行登录，将返回的token写到Cookie中**，下次访问时则把Cookie带上

* 到这里，其实我们会发现其实就两个变化：

  - **将登陆功能抽取为一个系统（SSO），其他系统请求SSO进行登录**
  - **本来将用户信息存到Session，现在将用户信息存到Redis**

  ```java
  // 登录功能(SSO单独的服务)
  @Override
  public TaotaoResult login(String username, String password) throws Exception {
      //登录成功，把用户信息写入redis
      //生成一个用户token
      String token = UUID.randomUUID().toString();
      jedisCluster.set(USER_TOKEN_KEY + ":" + token, JsonUtils.objectToJson(user));
      //设置session过期时间
      jedisCluster.expire(USER_TOKEN_KEY + ":" + token, SESSION_EXPIRE_TIME);
      return TaotaoResult.ok(token);
  }
  ```

## Cookie跨域的问题

1. 服务端将Cookie写到客户端后，客户端对Cookie进行解析，将Token解析出来，此后请求都把这个Token带上就行了
2. 多个域名共享Cookie，在写到客户端的时候设置Cookie的domain。
   * `cookie.setDomain(".onmpw.com");`
3. 将Token保存在SessionStroage中（不依赖Cookie就没有跨域的问题了）

## [CAS原理](https://mp.weixin.qq.com/s/drPVkRbCsDIlX6Ls2pDmqA)

* sso认证中心发现用户未登录，将用户引导至登录页面，用户进行输入用户名和密码进行登录，用户与认证中心建立**全局会话（生成一份Token，写到Cookie中，保存在浏览器上）**

  ![img](https://mmbiz.qpic.cn/mmbiz_jpg/2BGWl1qPxib1X4icuB3icPa8ibibRK0f3ibbbXXMLo4M58VodibVqdXdTNSrLHV6nRkgIicjeRjjprKHw96E2Apuv4NqOg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

* 随后，认证中心**重定向回系统A**，并把Token携带过去给系统A，重定向的地址如下：

  > www.java3y.com?token=xxxxxxx

* ![img](https://mmbiz.qpic.cn/mmbiz_jpg/2BGWl1qPxib1X4icuB3icPa8ibibRK0f3ibbbXIcTW7laczNjxRPff33UGJbVT1AaSsShJib6dC8ZSQUv3Y4Imzicf8tVg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# [如何保证消息顺序消费](https://www.liangzl.com/get-article-detail-155349.html)

* 生产者消费者一般需要保证顺序消息的话，可能就是一个业务场景下的，比如订单的创建、支付、发货、收货。

* 那这些东西是不是一个订单号呢？一个订单的肯定是一个订单号的说，那简单了呀。

* **一个topic下有多个队列**，为了保证发送有序，**RocketMQ**提供了**MessageQueueSelector**队列选择机制，他有三种实现:

![img](https://img-blog.csdnimg.cn/20181128124324615.png)

* **RocketMQ**仅保证顺序发送，顺序消费由消费者业务保证
* **Tip**：我写到这点的时候人才群里也有人问我，一个队列有序出去，一个消费者消费不就好了，我想说的是**消费者是多线程**的，你消息是有序的给他的，你能保证他是有序的处理的？还是一个消费成功了再发下一个**稳妥**。

# [如何解决重复下单问题](https://blog.52itstyle.vip/archives/3391/)

* 消息队列，100件商品，设置200个队列长度，设置商品 ID + 用户 ID 联合主键，确保一个用户只能秒杀一件商品。如果进入队列的前一百个请求有重复抢购行为，前台提示用户秒杀失败，100+后的队列补入数据**。基于前台的限流 + 人机验证码**，重复秒杀的请求应该不会很多，当然，为了确保不能少买，可以增加商品队列的长度。
* 若用消息做redis的set操作,set本身幂等,可解决重复下单问题
* 联合主键不自增
  * `userId_phoneNum`

# [如何防止超卖(减库存设计)](https://cnsyear.com/posts/daf64fef.html)

* ##### 直接减库存

* ##### 支付成功减库存

* ##### 预扣库存(使用这个)

  * 用户下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在用户付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。
  * 针对恶意下单这种情况，虽然把有效的付款时间设置为 10 分钟，但是恶意买家完全可以在10分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。
  * 反作弊的措施：给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买 3件），以及对重复下单不付款的操作进行次数限制等。

# 若一个用户多次抢购同一件商品导致主键冲突报错怎么办

* 通过ignore实现主键冲突直接返回0表示该SQL执行失败

```sql
insert ignore into seckill_order(seckill_id,money,user_phone) values (....)
```

# Redis中存储的数据

```properties
# 1. redis中缓存通过用户手机号码获取的用户信息
key: SkUserKeyPrefix:id_{phone}
value: {SeckillUser}
expire: 0

# 2. redis中通过缓存的token获取用户信息
key: SkUserKeyPrefix:token_{token}
value: {SeckillUser}
expire: 30min

# 3. redis中存储的商品列表页面
key: GoodsKeyPrefix:goodsListHtml
value: {html}
expire: 1min

# 4. redis中存储验证码结果
key: SkKeyPrefix:verifyResult_{uuid}_{goodsId}
value: {verifyResult}
expire: 5min

# 5. redis中存储随机秒杀地址
key: SkKeyPrefix:skPath_{uuid}_{goodsId}
value: {path}
expire: 1min

# 6. redis中存储用户一段时间内的访问次数
key: AccessKeyPrefix:access_{URI}_{phone}
value: {count}
expire: {@AccessLimit#seconds}

# 7. redis中存储的随机秒杀地址
key: SkKeyPrefix:skPath_{userId}_{goodsId}
value: {path}
expire: 1 min

# 8. redis中存储的在系统加载时从db读取的商品库存数量
key: GoodsKeyPrefix:goodsStock_{goodsId}
value: {stock}
expire: 0

# 9. redis中存储的订单信息
key: OrderKeyPrefix:SK_ORDER:{userId}_{goodsId}
value: {SeckillOrder}
expire: 0
```



# Redis缓存未更新问题

* 问题描述

  * 前端访问Redis缓存，后端数据库修改后，前端未能更新

* 解决

  * 手动清空Redis缓存

    ```redis
    flushall
    ```

# 如何防止链接暴露

* **接口防刷**，在高并发模式下，需单独开发一个方法保证用户抢购公平性
* **下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到**。

**如何接口防刷**

* 首先要保证商品处于秒杀状态
  * 秒杀开始时间<当前时间，秒杀截止时间>当前时间
* 保证一个用户抢购到一件商品，同一用户只能有唯一的一个URL秒杀地址，不同用户间秒杀地址不同，且配合订单表`seckill_order`中联合主键配置实现

# 两个事务合并

* 减库存与记录购买明细 两个操作合并为一个接口方法：执行秒杀的操作
* 使用注解式事务
  * 保证事务方法的执行时间尽可能短
    * 不要穿插其他RPC/HTTP请求
  * 不是所有的方法都需要事务控制
    * 如只有一条修改的操作 ，只读操作是不需事务控制
  * Spring默认只对运行期异常进行事务回滚操作，对于编译异常是不回滚的
    * 尽量将编译期异常转为运行时异常



# 缓存一致性问题

* 先更新数据库再更新缓存
* 利用数据库的Binlog更新缓存

# 为何先记录订单再减少库存

* 优化sql操作，先记录会降低rowLock时间

# 如何降低update对rowLock的持有时间

* 执行一条update语句需要获得mysql的行锁rowLock
* 优化
  * 调用update和insert操作执行顺序	
    * 我们通过`insert ignore into xx`方式避免重复秒杀，先执行insert语句可以在插入时就排除可能存在重复秒杀的操作，这样就不用再执行更新操作了，在一定程度上降低了一倍的rowLock持有时间

# 高并发下唯一订单号生成

* 方案一

  * 使用` Java.Util`包下的UUID类`UUID.randomUUID().hashCode()`

* 方案二

  * 使用的是当前时间，包括毫秒数、纳秒数，不需要数据库参与计算，性能不用说。

  * ```java
    public static String genId(String machineId) {
            String orderId = machineId +
                            (System.currentTimeMillis() + "").substring(1) +
                            (System.nanoTime() + "").substring(7, 10);
            System.out.println(orderId);
            return orderId;
        }
    ```

# [项目遇到的问题](https://mp.weixin.qq.com/s/-DZj158-LOQmnCayf1_n3A)

> 我在使用 Redis 对常用数据进行缓冲的过程中出现了缓存穿透问题。然后，我通过谷歌搜索相关的解决方案来解决的。

* 什么是缓存穿透以及你最后的解决办法

> 缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。
>
> 总结一下就是：
>
> 缓存层不命中。
> 存储层不命中，不将空结果写回缓存。
> 返回空结果给客户端。
> 一般 MySQL 默认的最大连接数在 150 左右，这个可以通过 show variables like '%max_connections%';命令来查看。最大连接数一个还只是一个指标，cpu，内存，磁盘，网络等物理条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 的并发请求就能打死大部分数据库了。

* 解决办法

> 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。
>
> 参数校验通过的情况还是会出现缓存穿透，我们还可以通过以下几个方案来解决这个问题：
>
> 
>
> **1）缓存无效 key** : 如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下：`SET key value EX 10086`。这种方式可以解决请求的 key 变化不频繁的情况，如何黑客恶意攻击，每次构建的不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。
>
> 另外，这里多说一嘴，一般情况下我们是这样设计 key 的：`表名:列名:主键名:主键值`。
>
> 
>
> **2）布隆过滤器：** 布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。

* 不错不错！你还知道布隆过滤器啊！来给我谈一谈。

> 布隆过滤器的本质实际上是 “位(bit)数组”，也就是说每一个存入布隆过滤器的数据都只占一位。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。
>
> 当一个元素加入布隆过滤器中的时候，会进行如下操作：
>
> 1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
> 2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。
>
> 综上，我们可以得出：**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

*  看来你对布隆过滤器了解的还挺不错的嘛！那你快说说你最后是怎么利用它来解决缓存穿透的。

  > 知道了布隆过滤器的原理就之后就很容易做了。我是利用 Redis 布隆过滤器来做的。我把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，我会先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。总结一下就是下面这张图(这张图片不是我画的，为了省事直接在网上找的)
  >
  > ![img](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TxReHn5AXmsdWIlDhe6MNFyOlDDtqIPdib1txArIpbo8DA64cj2Sia2WTibOOZLYsM24aA2eYFvc0VXQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

# JMeter压测

- Jmeter压测
  - 阿里云学生版服务器走mysql查询大概是80QPS，走redis查询大概是200QPS，写了一个脚本来记录top命令，发现CPU和MEM占用率都在50%左右，那瓶颈是什么呢？后来发现，服务器的带宽是1M的，无法支持大规模并发，因此转而在本机实现。
  - 本机瓶颈在CPU，因为本机既要做压测，又要充当服务器，实测下来mysql和redis大概都是800到1000的QPS。
    

# Redis压测

> Redis-benchmark -h 127.0.0.1 -p 6379 -c 100 -n 100000

- 10w请求完成时间0.69s，每秒QPS14w请求

# 前后端交互接口逻辑实现

[TOC]

## 用户登录逻辑

请求url：`/user/login`

1. 通过请求参数解析器获取用户请求参数，获取用户名和用户密码，判断用户是否存在（首先从缓存中获取该用户是否存在，如果用户存在，则从缓存中获取，如果不存在，则从db中获取，并将获取得到的用户信息存储到缓存中，以便下次获取用户信息时直接从缓存中获取）；如果用户不存在，则向客户端发送用户不存在的消息，如果用户存在，进入2；
2. 检验用户输入密码是否正确，如果用户输入密码不正确，则返回用户密码不正确的消息给客户端，否则，如果用户密码校验正确，进入3；
3. 生成token，并存储在缓存中，这样，下次访问的时候，就可以从缓存中查询token，直接通过token校验用户是否合法，从而防止重复登录，token存储到缓存中后，进入4；
4. 生成cookie对象，包装token，然后将cookie对象通过response返回给客户端，cookie有效期和缓存中的token有效期一致；
5. 用户在cookie有效期内发出资源请求时，服务端从url或者set-cookie字段获取token信息，通过token从缓存中获取用户信息，如果获取的用户信息存在，则表明是同一个用户在访问，否则，如果用户不存在，则表名token不正确，请求非法；
6. 从缓存中获取用户信息存在时，需要重新在缓存中设置一下该token，以达到记录最新访问时间，根据过期时间延长cookie有效期的目的。

**登录过程总结：**

对需要进行用户鉴权的访问，在controller层的方法上添加LoginVo参数，这样，用户请求都会使用自定义的参数解析器处理LoginVo，在处理的时候完成鉴权工作。

为了方式用户每次请求都从db中获取用户信息，在第一次登录成功的时候将用户信息从数据库中查询出来并缓存在redis中，并将其过期时间设置为0，即永久有效，那么，在往后该用户访问并需要获取用户信息的时候，就可以直接从缓存中获取用户信息，而不用反复从db中获取，从而减少不必要的请求落到db上。本身用户数据就属于不会经常变动却需要经常读取的数据，放在缓存中再合适不过了，不过，在用户数据更改的时候，需要考虑缓存和数据库的数据一致性。

用户数据通过两种方式缓存在redis中，一种是以phone为key，另一种是以token为key，缓存的数据都是用户信息，唯一不一样的是，它们的过期时间不同。token具有时效性，因此过期时间设置得比较短，为30min。而另一份以phone为key的用户信息永久保留在redis中，用户减少对db的访问。所以，两份数据的意义是不一样的，以token为key的用户信息缓存用户鉴权，而以phone为key的用户信息缓存用于查询。

redis中缓存通过用户手机号码获取的用户信息：

```properties
key: SkUserKeyPrefix:id_{phone}
value: {SeckillUser}
expire: 0
```

redis中通过缓存的token获取用户信息：

```properties
key: SkUserKeyPrefix:token_{token}
value: {SeckillUser}
expire: 30min
```

## 商品列表请求逻辑

商品列表请求url：`goods/goodsList`

1. 首先从缓存中查询商品列表页面的html文件，如果存在，则直接返回给客户端，如果不存在，进入2；
2. 从数据库中查询所有商品信息，然后通过thymeleafViewResolver渲染页面商品列表页面，通过将列表页面存储到缓存中，以便下次访问商品列表页面时直接从缓存中获取；

**商品列表请求逻辑总结：**

商品列表请求逻辑相对简单，只是在处理的时候，将商品列表模板渲染过程从自动变为手动，之所以这样做是希望在redis中缓存该页面，如果自动渲染，那么该页面会在每次客户端发出请求时都渲染一次，列表页的数据实际上除了库存信息以外，其他信息都是不变的，因此，可以将其缓存起来。如果要缓存页面信息到redis中，必须获取该页面，显然，自动渲染时没法得到页面的，所以手动显示地渲染，得到列表页面，并缓存。

值得注意的一点是，redis在缓存列表html时，因为列表页面的库存信息实际上会变化，如果redis中缓存页面过期时间设置过长，则会造成db和缓存的数据不一致，所以，缓存时间的设置是一个关键，过期就需要从db中获取，本项目将缓存过期施加设置为1min，也就是说，在1min内，用户看到的数据和db的数据不会过于不一致，但实际上还是会有一定的不一致。当然，这个过期时间越小越好，但是这就会造成对db的频繁访问，造成db压力过大，影响核心业务，所以，需要在过期时间和db访问压力之间做一个权衡。

通过上述可知，为了库存数据更加实时，db查询商品列表信息越小，需要进一步优化。（目前思路：将商品信息也预存到redis中，但是这样有可能会出现存储空间不足的情况）

redis中存储的商品列表页面为：

```properties
key: GoodsKeyPrefix:goodsListHtml
value: {html}
expire: 1min
```

## 商品详情请求逻辑

商品详情请求url：`goods/getDetails/{goodsId}`

1. 从db中获取获取商品详情；
2. 计算商品秒杀状态以及秒杀剩余时间；
3. 封装商品秒杀状态、秒杀剩余时间和秒杀商品详细信息到vo，并返回给客户端，由客户端获取该vo的json数据并渲染。

**商品详情请求逻辑总结**

因为商品详细信息中的库存、秒杀状态在详情页面的时候需要近乎实时的获取，这样可以给用户一个更好的体验。所以，需要每次都从db中获取该商品的详细信息。

秒杀商品和商品是分别使用两个表存储的，这样做的目的在于：商品列表包含了商品的详细信息，秒杀商品存储的信息为和秒杀有关的信息，如果使用同一个表存储商品的所有信息（包含秒杀信息），那么，在向表写入数据的时候，就会造成过多的请求阻塞地获取锁，而实际上，秒杀业务下，写入操作多为和秒杀有关的字段，如果将这些字段分离处理，商品表主要用于读，而秒杀商品列表用于秒杀业务，这样就可以提高数据库的吞吐量。

**改进**：是否可以将秒杀商品表的关键信息预存到redis中？

## 获取验证码图片逻辑

获取验证码url：`/seckill/verifyCode`

1. 服务端收到请求，生成验证码，并通过ScriptEngine引擎计算验证码结果，然后将验证码结果存储于缓存中；
2. 将验证码图片以`JPEG`格式返回给客户端；

redis中存储验证码结果：

```properties
key: SkKeyPrefix:verifyResult_{uuid}_{goodsId}
value: {verifyResult}
expire: 5min
```

## 获取秒杀接口地址逻辑

获取秒杀接口地址请求url：`/seckill/path`

1. 根据用户输入的验证码值和goodsId从缓存中获取验证码结果，校验验证码是够正确，如果校验失败，则返回用户重新输入提示，如果校验成功，则创建随机秒杀地址；
2. 使用UUID工具生成随机秒杀地址，并将随机秒杀地址存储于缓存中；
3. 返回给客户端随机秒杀地址。

**获取秒杀接口地址总结：**

之所以引入随机秒杀地址，原因如下：

如果秒杀接口的地址为静态地址，那么用户可以轻易的使用接口地址完成进行恶意秒杀，这样会使得参与秒杀的用户参与度不搞，达不到业务目的，引入随机地址则可以很好的规避这个问题。

秒杀地址的生成在验证码校验之后，这就是说，一定需要在验证码输入正确的情况下才能获取到随机秒杀地址。

除了上述的通过验证码保护秒杀请求地址外，还引入了接口防刷机制防止用户过于频繁的提交请求。

redis中存储的随机秒杀地址用户秒杀请求时的地址校验。

redis中存储随机秒杀地址：

```properties
key: SkKeyPrefix:skPath_{uuid}_{goodsId}
value: {path}
expire: 1min
```

## 秒杀接口防刷机制

1. 服务器拦截用户请求，判断请求处理器上是否有@accessLimit注解，如果没有，直接放行，如果有，则进入2；
2. 获取注解参数，包括最大访问次数、时间间隔；
3. 对于第一次访问有@accessLimit注解的方法，将随机url地址存储到redis中，并设置过期时间为注解上的时间间隔。
4. 对第二次请求，如果redis中统计的请求次数没有达到最大值，则自增，如果达到最大值，则向用户发出频繁请求响应。

**总结**

```java
@AccessLimit(seconds = 5, maxAccessCount = 5, needLogin = true)
```

有上述注解的方法将会被拦截，其含义为：在5s内，最大访问次数为5次。

redis中存储用户一段时间内的访问次数：

```properties
key: AccessKeyPrefix:access_{URI}_{phone}
value: {count}
expire: {@AccessLimit#seconds}
```

## 秒杀请求处理逻辑

秒杀请求url：`/seckill/{path}/doSeckill`

1. 根据userId和goodsId从redis中读取{path}，校验随机秒杀接口地址是否一致，如果不一致，则说明客户端发送的秒杀请求非法，随机秒杀地址被客户端更改。如果一致，则进入2；
2. 系统在启动的时候，已经从数据库中加载所有秒杀商品的库存信息，标记库存的有无到本地内存（HashMap）中和记录具体商品的库存到redis中，所以，这一步在内存标记中判断是否该商品还有库存，如果没有，直接驳回请求，如果有，则进入3；
3. redis中在最开始系统启动时记录了商品的库存信息，所以，可以通过redis预减库存，而不需要在这个时候到db中减库存，如果库存预减到不大于0，表明之前的请求已经将商品库存消耗完成，此时，在内存中标记该商品已经完成秒杀。如果预减库存成功，则将请求放行到4；
4. 根据useId和goodsId从redis中查询秒杀订单信息，如果存在，则说明，该用户已经完成该商品的秒杀，直接驳回请求，否则，放行请求到5；
5. 根据useId和goodsId从数据库中获取订单信息，如果存在，则直接驳回请求，否则放行请求到6；
6. 生成秒杀请求消息，放入队列中，将秒杀请求交由队列处理。

**秒杀请求处理逻辑总结：**

一句话，使用内存标记和缓存将秒杀请求拦截在db上游，防止大并发下的秒杀请求落到db。

为什么有了内存标记，预减库存，订单缓存的情形下，还要在缓存中订单不存在的情况下从db读取订单信息，而在队列中又有从db读取订单信息拦截请求的操作？

**这个问题是由大并发导致的**，实际上，内存标记，可以阻挡一部分请求，然后通过redis预减库存，也只能拦截一部分请求。考虑一种情形：

假设用户以极快的速度同时发出两次请求，两次请求有相同的userId和goodsId，前一次请求完成秒杀时，后一次请求正好从db中读取订单信息，那么可见，后一次请求可以读到完成秒杀的订单，这样就可以将该用户请求拦截下来，不用发送到消息队列中处理，减轻消息队列的负载。

另一种情形，后一次请求没有从数据库中读取到该用户的订单信息，也就是执行时间稍微超前于前一次请求写入订单的时机，那么实际上后一次请求也是无效请求，会发送到消息队列处理，再看消息队列的消费者，**消费者也会先从缓存再从db中读取该请求的秒杀订单信息，这样就可以将这个无效请求拦截下来，不用落到db上，达到减轻db负载的压力**。

这就是为什么会**两次**从redis中读取订单信息，在redis中订单信息无效时从db读订单信息；一次发生在秒杀请求发送到消息队列之前，一次发生在发送到消息队列之后（即真正做秒杀之前）。目的即使为了阻挡无效的请求落到db上。

redis中存储的随机秒杀地址为：

```properties
key: SkKeyPrefix:skPath_{userId}_{goodsId}
value: {path}
expire: 1 min
```

redis中存储的在系统加载时从db读取的商品库存信息：

```properties
key: GoodsKeyPrefix:goodsStock_{goodsId}
value: {stock}
expire: 0
```

## 消息队列处理秒杀请求的过程（秒杀业务的核心）

1. 消息队列收到秒杀消息（SkMessage[user, goodsId]）后，通过goodsId从DB中查询该商品的库存信息，如果库存不大于0，则直接返回，反之，则表明该商品还有库存，进入2；

2. 通过userId和goodsId从redis中查询秒杀订单信息，如果查询结果不为空，则说明该用户已经对该商品进行过秒杀，直接返回；反之，可能因为缓存有效期的问题，使得缓存中的秒杀订单信息无效，进入3；

3. 根据userId和goodsId从DB中获取秒杀订单信息，如果秒杀订单信息不为空，则说明该用户已经完成该商品的秒杀，直接将秒杀请求驳回，如果查询的秒杀订单信息为空。则说明该用户为对该商品进行过秒杀，进入4；

4. 这一步为秒杀业务逻辑的关键，分为三步：从商品表中减该商品的库存，生成订单信息写入秒杀订单表和订单表中；

5. 首先，减库存。在该商品库存不为零的时候，返回更新记得记录id，大于0则表明更新成，即减库成功；反之，库存为0，减库存失败，在redis中标记该商品已没有库存。

   ```mysql
   UPDATE seckill_goods SET stock_count = stock_count-1 
   WHERE goods_id=#{goodsId} AND stock_count > 0
   ```

6. 如果5中减库存成功，则创建订单，将订单写入秒杀订单表和订单信息表中，并且，将生成的订单信息在db写操作完成后存储到redis中，这样，下次同一用户对同一商品发起秒杀请求时，直接使用redis中的数据就可以判断其完成了秒杀，而不用再从db中读数据判断该用户是否对该商品已经完成了秒杀；

7. 需要注意的是，秒杀动作的关键三步：减库存，生成订单记录插入订单信息表和秒杀订单表构成事务，需要使用Spring的@Transactional注解处理事务。

**消息队列处理秒杀请求的过程总结：**

在秒杀请求中，我们使用大量的缓存将秒杀请求阻挡在db外，真正落入db的请求应该尽可能的小，这样可以防止秒杀请求直接透穿DB，从而减轻db压力。

实际上，秒杀商品有限，库存也有限，如果将秒杀请求直接落到db，是非常不合理的，考虑一种情形，某件秒杀商品的库存为100，在秒杀开始的时候，瞬间的秒杀请求并发量为5W，可以想象，数据库是无法承担如此高的并大量的，另外，5w个秒杀请求，实际只有100个秒杀请求有效，多出来的请求只会无端对数据库造成访问压力，而对业务毫不相关。

消息队列使用redis来拦截秒杀请求，redis中缓存何种数据是非常重要的。消息队列处理秒杀请求时只会从缓存中读/写订单信息，写缓存发生在db写订单完成后，读缓存发生在对db写之前。写redis发生在db之后，可以保证缓存和db中的数据的一致性，读redis发生在写db之前，可以用来阻挡无用请求，减轻db压力。这个地方，并没有做到缓存于dB的强一致性，只能保证最终一致性。

redis中存储的订单信息为：

```properties
key: OrderKeyPrefix:SK_ORDER:{userId}_{goodsId}
value: {SeckillOrder}
expire: 0
```





