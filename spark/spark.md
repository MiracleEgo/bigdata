# Spark程序的调度过程

* 用户用spark-submit提交程序
* spark-submit在同一节点（客户端模式）或集群（集群模式）启动驱动并调用用户main()
* 



* 驱动进程联系集群管理器，根据提供的配置参数来请求启动执行进程JVM所需的资源。
* 集群管理器在工作机节点上启动执行进程JVM
* 驱动进程扫描用户应用程序。根据程序中的RDD动作和变换，Spark会创建一个运算图。
* 当调用一个动作（如collect）时，图会被提交到一个有向无环图（DAG）调度程序。DAG调度程序将运算图划分成一些阶段。
* 一个阶段由基于输入数据分区的任务组成。DAG调度程序会通过流水线把运算符连一起，从而优化运算图。例如，很多映射（map）运算符可以调度到一个阶段中。为种优化对Spark的性能是很关键的。DAG调度程序的最终结果是一组阶段。
* 这些阶段会被传递到任务调度程序。任务调度程序通过集群管理器（Spark Srandalone/Yarn/Mesos）启动任务。任务调度器并不知道阶段之间的依赖性。
* 任务在执行进程上运行，从而计算和保存结果。
* 如果驱动进程的main退出，或者它调用了SparkContext.stop()，它就会终止执行进程并从集群管理器释放资源。